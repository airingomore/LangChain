{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731ab4e1",
   "metadata": {},
   "source": [
    "# LangChain Basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73db84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebd75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15bc749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8facdff2",
   "metadata": {},
   "source": [
    "### Python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f32dd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "\n",
    "#os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5d85f",
   "metadata": {},
   "source": [
    "### LLM Models (Wrappers): GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aabf73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 512, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f47699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantum mechanics is a set of principles describing the behavior of matter and energy at the atomic and subatomic scales.\n"
     ]
    }
   ],
   "source": [
    "output = llm('Explain quantum mechanics in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5672df0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens('Explain quantum mechanics in one sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d41e0941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\nParis', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe formula for the area of a circle is A = πr², where A is the area, π is 3.14, and r is the radius of the circle.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "output = llm.generate(['... is the capital of France', \n",
    "                   'What is the formula for the area of the circle'])\n",
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e528a0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The formula for the area of a circle is A = πr², where A is the area, π is 3.14, and r is the radius of the circle.\n"
     ]
    }
   ],
   "source": [
    "# Answer of the second question\n",
    "print(output.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe27226e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a2038d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['Write an original tagline for burger restaurant']*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0091f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Taste the flavor of freshness in every bite!\"\n",
      "\n",
      "\n",
      "\"Tastes good, feels good - burgers at their best!\"\n",
      "\n",
      "\n",
      "\"Taste the Juicy Difference at Our Burger Joint!\"\n"
     ]
    }
   ],
   "source": [
    "for o in output.generations:\n",
    "    print(o[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc2751",
   "metadata": {},
   "source": [
    "### ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b031c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6f65929",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in Spanish'),\n",
    "    HumanMessage(content='Explain quantum mechanics in one sentence')\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2685cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='La mecánica cuántica es una teoría física que describe el comportamiento de las partículas subatómicas, las cuales pueden existir en múltiples estados al mismo tiempo y solo se determinan al ser observadas.'\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa68f5",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e531499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e4cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['virus', 'language'] template='You are an experienced virologist. Write a few sentences about the following {virus} in {language}'\n"
     ]
    }
   ],
   "source": [
    "template = '''You are an experienced virologist. Write a few sentences about the following {virus} in {language}'''\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus','language'],\n",
    "    template=template\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ad5e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
    "output = llm(prompt.format(virus='ebola', language='spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de0d487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Como virologista experimentado, sé que el ébola es un virus letal que puede causar enfermedades graves y a veces letales. El ébola se transmite principalmente a través de contacto directo con los fluidos corporales de una persona infectada. Los síntomas pueden incluir fiebre, dolor de cabeza, dolor muscular y fatiga. La única forma de prevenir la propagación del ébola es mediante la implementación de prácticas de higiene adecuadas y el aislamiento de los individuos infectados.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5eb559",
   "metadata": {},
   "source": [
    "### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db23ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "\n",
    "template = '''You are an experienced virologist. Write a few sentences about the following {virus} in {language}'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus','language'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run({'virus':'HSV', 'language':'spanish'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48c6436a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El virus del herpes simple (HSV, por sus siglas en inglés) es un virus altamente contagioso que afecta principalmente a los humanos. Hay dos tipos de HSV: el HSV-1, que suele causar infecciones orales como el herpes labial, y el HSV-2, que se asocia comúnmente con las infecciones genitales. Ambos tipos de HSV pueden causar brotes recurrentes a lo largo de la vida de una persona infectada. Actualmente, no existe una cura para el HSV, pero los antivirales pueden ayudar a controlar los síntomas y reducir la frecuencia de los brotes.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86622f08",
   "metadata": {},
   "source": [
    "### Sequencial Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e121b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "def linear_regression(x_values, y_values):\n",
      "    \"\"\"\n",
      "    Implements the concept of linear regression\n",
      "    :param x_values: List of x values\n",
      "    :param y_values: List of y values\n",
      "    :return: A list of coefficients for the linear regression\n",
      "    \"\"\"\n",
      "    x_mean = sum(x_values) / len(x_values)\n",
      "    y_mean = sum(y_values) / len(y_values)\n",
      "\n",
      "    numerator = sum(x*y for x, y in zip(x_values, y_values)) - len(x_values) * x_mean * y_mean\n",
      "    denominator = sum(x**2 for x in x_values) - len(x_values) * x_mean**2\n",
      "\n",
      "    slope = numerator / denominator\n",
      "    intercept = y_mean - (slope * x_mean)\n",
      "\n",
      "    return [intercept, slope]\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe function `linear_regression` implements the concept of linear regression. Linear regression is a statistical technique used to find the best-fitting line that describes the relationship between two variables. In this case, the function takes in a list of x values and a list of corresponding y values.\n",
      "\n",
      "The function starts by calculating the mean of both the x and y values by summing all the values and dividing by the length of the respective lists. These mean values will be used in further calculations.\n",
      "\n",
      "Next, the function calculates the numerator of the equation used to find the slope of the linear regression line. The numerator is calculated as the sum of the products of each x value and its corresponding y value, minus the product of the means of the x and y values, and then multiplied by the length of the x values list.\n",
      "\n",
      "Then, the function calculates the denominator of the slope equation. The denominator is calculated as the sum of the squares of each x value, minus the square of the mean of the x values, and then multiplied by the length of the x values list.\n",
      "\n",
      "After obtaining the numerator and denominator, the function calculates the slope of the linear regression line by dividing the numerator by the denominator.\n",
      "\n",
      "Finally, the function calculates the intercept of the linear regression line by subtracting the product of the slope and the mean of the x values from the mean of the y values.\n",
      "\n",
      "The function returns a list of the intercept and slope coefficients for the linear regression line.\n",
      "\n",
      "In summary, the `linear_regression` function performs the necessary calculations to determine the best-fitting line for a given set of x and y values using linear regression.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an expereinced scientist and Python programmer. \n",
    "        Write a function that implements the concept of {concept}.'''\n",
    ")\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1,chain2], verbose=True)\n",
    "output = overall_chain.run('linear regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd82daa",
   "metadata": {},
   "source": [
    "### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78095979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2d95e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to calculate the factorial of 20 and then take the square root\n",
      "Action: Python_REPL\n",
      "Action Input: from math import factorial\n",
      "               print(round(factorial(20)**0.5, 4))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIndentationError('unexpected indent', ('<string>', 2, 15, '               print(round(factorial(20)**0.5, 4))\\n', 2, -1))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to remove the extra indentation\n",
      "Action: Python_REPL\n",
      "Action Input: from math import factorial\n",
      "print(round(factorial(20)**0.5, 4))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1559776268.6285\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 1559776268.6285\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1559776268.6285'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "agent_executer = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "agent_executer.run('Calculate the squate root of the factorial fo 20 \\\n",
    "                   and display it with 4 decimal points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "127a4808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to calculate this\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'146306.05007233328'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.run('What is the answer to 5.1 ** 7.3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
