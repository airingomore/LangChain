{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731ab4e1",
   "metadata": {},
   "source": [
    "# LangChain Basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73db84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebd75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15bc749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8facdff2",
   "metadata": {},
   "source": [
    "### Python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f32dd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "\n",
    "#os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5d85f",
   "metadata": {},
   "source": [
    "### LLM Models (Wrappers): GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aabf73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 512, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f47699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantum mechanics is a branch of physics that describes the behavior of matter on the atomic and subatomic level.\n"
     ]
    }
   ],
   "source": [
    "output = llm('Explain quantum mechanics in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5672df0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens('Explain quantum mechanics in one sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41e0941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\nParis', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='?\\n\\nThe formula for the area of a circle is A = πr^2, where r is the radius of the circle.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "output = llm.generate(['... is the capital of France', \n",
    "                   'What is the formula for the area of the circle'])\n",
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e528a0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "The formula for the area of a circle is A = πr^2, where r is the radius of the circle.\n"
     ]
    }
   ],
   "source": [
    "# Answer of the second question\n",
    "print(output.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe27226e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a2038d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['Write an original tagline for burger restaurant']*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0091f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Taste the Difference at Burger Heaven!\"\n",
      "\n",
      "\n",
      "\"Sink your teeth into a delicious burger experience!\"\n",
      "\n",
      "\n",
      "\"Taste the Juiciest Burgers in Town!\"\n"
     ]
    }
   ],
   "source": [
    "for o in output.generations:\n",
    "    print(o[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc2751",
   "metadata": {},
   "source": [
    "### ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b031c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6f65929",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in Spanish'),\n",
    "    HumanMessage(content='Explain quantum mechanics in one sentence')\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2685cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='La mecánica cuántica es una teoría física que describe el comportamiento de las partículas subatómicas y sus interacciones a través de principios como la superposición, el entrelazamiento y la dualidad onda-partícula.'\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa68f5",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e531499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03e4cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['virus', 'language'] template='You are an experienced virologist. Write a few sentences about the following {virus} in {language}'\n"
     ]
    }
   ],
   "source": [
    "template = '''You are an experienced virologist. Write a few sentences about the following {virus} in {language}'''\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus','language'],\n",
    "    template=template\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ad5e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
    "output = llm(prompt.format(virus='ebola', language='spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de0d487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Como experto en la materia de la virología, sé que el ébola es una enfermedad viral grave que causa fiebre hemorrágica y se transmite a través de contacto con fluidos corporales de personas infectadas con el virus. Se ha descubierto que el ébola se origina en África Occidental, pero también se ha reportado en otros países. Es importante tomar precauciones para prevenir la propagación de este virus, como evitar el contacto con personas enfermas y el uso de medidas de protección adecuadas.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5eb559",
   "metadata": {},
   "source": [
    "### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db23ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "\n",
    "template = '''You are an experienced virologist. Write a few sentences about the following {virus} in {language}'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus','language'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run({'virus':'HSV', 'language':'spanish'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48c6436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El HSV, o virus del herpes simple, es un virus altamente contagioso que afecta principalmente a los humanos. Hay dos tipos de HSV: el HSV-1, que generalmente causa herpes labial y ocasionalmente herpes genital, y el HSV-2, que es la principal causa de herpes genital. Estos virus se transmiten a través del contacto directo con una persona infectada o a través de objetos contaminados. Aunque no hay cura para el HSV, existen tratamientos antivirales que pueden ayudar a reducir la frecuencia y la gravedad de los brotes.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86622f08",
   "metadata": {},
   "source": [
    "### Sequencial Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e121b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "def linear_regression(x_values, y_values):\n",
      "    \"\"\"\n",
      "    A function that implements the concept of linear regression. \n",
      "    Parameters: \n",
      "    x_values (list): A list of x values \n",
      "    y_values (list): A list of y values\n",
      "    \n",
      "    Returns: \n",
      "    (float, float): The slope and intercept of the regression line\n",
      "    \"\"\"\n",
      "    x_mean = sum(x_values) / len(x_values)\n",
      "    y_mean = sum(y_values) / len(y_values)\n",
      "    \n",
      "    numerator = 0\n",
      "    denominator = 0\n",
      "    for i in range(0, len(x_values)):\n",
      "        numerator += (x_values[i] - x_mean) * (y_values[i] - y_mean)\n",
      "        denominator += (x_values[i] - x_mean) ** 2\n",
      "    \n",
      "    slope = numerator / denominator\n",
      "    intercept = y_mean - slope * x_mean\n",
      "    \n",
      "    return (slope, intercept)\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe `linear_regression` function is a Python function that implements the concept of linear regression. It takes in two parameters, `x_values` and `y_values`, which are both lists of numerical values. These lists represent the x and y coordinates of the data points that we want to perform linear regression on.\n",
      "\n",
      "The function computes the mean of the `x_values` and `y_values` using the `sum` function and dividing by the length of the list. The mean of `x_values` is stored in the variable `x_mean` and the mean of `y_values` is stored in the variable `y_mean`.\n",
      "\n",
      "Next, the function initializes two variables: `numerator` and `denominator` with initial values of 0. These variables will be used to calculate the slope and intercept of the regression line.\n",
      "\n",
      "The function then enters a loop that iterates over the indices of the `x_values` list. Inside the loop, it calculates the numerator and denominator of the slope formula for each data point. The numerator is updated by multiplying the difference between the current `x_values[i]` and `x_mean` with the difference between the corresponding `y_values[i]` and `y_mean`. The denominator is updated by adding the square of the difference between the current `x_values[i]` and `x_mean`.\n",
      "\n",
      "After the loop, the slope is calculated by dividing the numerator by the denominator. The intercept is calculated by subtracting the product of the slope and `x_mean` from `y_mean`.\n",
      "\n",
      "Finally, the function returns a tuple `(slope, intercept)`, representing the slope and intercept of the regression line.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an expereinced scientist and Python programmer. \n",
    "        Write a function that implements the concept of {concept}.'''\n",
    ")\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1,chain2], verbose=True)\n",
    "output = overall_chain.run('linear regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6404e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78095979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d95e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a4808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
