{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05eaa1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "# override=True is to refresh the variable in case it changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c8df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your prompt: light speed in vacuum\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human.\n",
      "Human: light speed in vacuum\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The speed of light in a vacuum is about 299,792 kilometers per second or approximately 186,282 miles per second. This is often rounded to 300,000 kilometers per second or 186,000 miles per second for simplicity. The speed of light is considered to be the fastest speed that anything can travel in the universe.\n",
      "--------------------------------------------------\n",
      "Your prompt: and what about light speed in water?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human.\n",
      "Human: light speed in vacuum\n",
      "AI: The speed of light in a vacuum is about 299,792 kilometers per second or approximately 186,282 miles per second. This is often rounded to 300,000 kilometers per second or 186,000 miles per second for simplicity. The speed of light is considered to be the fastest speed that anything can travel in the universe.\n",
      "Human: and what about light speed in water?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# use System Messages sets the behavior of the assistant from chain schema\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory, FileChatMessageHistory\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1)\n",
    "history = FileChatMessageHistory('chat_history.json')\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    chat_memory=history,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=['content'],\n",
    "    messages=[\n",
    "        SystemMessage(content='You are a chatbot having a conversation with a human.'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'), # where the memory will be stored\n",
    "        HumanMessagePromptTemplate.from_template('{content}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "while True:\n",
    "    content = input('Your prompt: ')\n",
    "    if content in ['quit','exit','bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "        \n",
    "    response = chain.run({'content': content})\n",
    "    print(response)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711192d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6387927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
