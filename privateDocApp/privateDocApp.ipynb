{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f537d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e8ebfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pypdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f221f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install docx2txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1d0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wikipedia -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64d001",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18cbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "    import os\n",
    "    name,extension = os.path.splitext(file)\n",
    "    \n",
    "    if extension == '.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        # each document contains the page, content and metadata with a page number\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    else:\n",
    "        print('Document format is not supported!')\n",
    "    \n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "def load_from_wikipedia(query,lang='en', load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query,lang=lang,load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eadc8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "980718bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total tokens: {total_tokens}')\n",
    "    print(f'Embeeding cost in USD: {total_tokens / 1000 * 0.0004:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "056833ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_of_fetch_embeddings(index_name):\n",
    "    \n",
    "    import pinecone \n",
    "    from langchain.vectorstores import Pinecone\n",
    "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "    \n",
    "    if index_name in pinecone.list_indexes():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings', end='')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('Ok')\n",
    "        \n",
    "    else:\n",
    "        print(f'Creating Index {index_name} and embeddings', end='')\n",
    "        pinecone.create_index(index_name, dimension=1536, metric='cosine')\n",
    "        vector_store = Pinecone.from_documents(chunks,embeddings, index_name=index_name)\n",
    "        print('Ok')\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab6946fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone \n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "\n",
    "    if index_name=='all':\n",
    "        indexes = pinecone.list_indexes()\n",
    "        print('Deleting all the indexes...')\n",
    "        for index in indexes:\n",
    "            pinecone.delete_index(index)\n",
    "        print('ok')\n",
    "    else:\n",
    "        print(f'Deleting inde {index_name}...', end='')\n",
    "        pinecone.delete_index(index)\n",
    "        print('ok')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c39fd3",
   "metadata": {},
   "source": [
    "## Running code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3126f08",
   "metadata": {},
   "source": [
    "### Uploading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34168e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_document('files/Análisis+de+un+sector+2.0.pdf')\n",
    "#print(data[1].page_content)\n",
    "#print(data[1].metadata)\n",
    "#print(f'You have {len(data)} pages in your data')\n",
    "#print(f'There are {len(data[2].page_content)} characters in the page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fec2f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/00217 - Vivir Sin Jefe - Sergio Fernández.pdf\n",
      "{'source': 'files/00217 - Vivir Sin Jefe - Sergio Fernández.pdf', 'page': 1}\n",
      "You have 138 pages in your data\n",
      "There are 82 characters in the page\n"
     ]
    }
   ],
   "source": [
    "data = load_document('files/00217 - Vivir Sin Jefe - Sergio Fernández.pdf')\n",
    "#print(data[1].page_content)\n",
    "print(data[1].metadata)\n",
    "print(f'You have {len(data)} pages in your data')\n",
    "print(f'There are {len(data[2].page_content)} characters in the page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10763297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_from_wikipedia('GPT-4', 'es')\n",
    "#print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbef9be",
   "metadata": {},
   "source": [
    "### Chunking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a26d5a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of chunks of 1367\n",
      "Jugar a ser usted de mayor \n",
      " \n",
      "Error 37. No dar la apariencia de estar siempre ocupado\n",
      "Creyendo apasionadamente en algo que aún no existe, lo creamos. Lo que no existe\n",
      "es aquello que no hemos deseado lo suficiente. (Pintada encontrada en Leicester\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(f'We have a total of chunks of {len(chunks)}')\n",
    "print(chunks[1000].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e2d44",
   "metadata": {},
   "source": [
    "### Calculating Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2eba3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 85574\n",
      "Embeeding cost in USD: 0.034230\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adad85d",
   "metadata": {},
   "source": [
    "### Embedding and Uploading to a Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "776ff8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all the indexes...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d0b44e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Index askadocument and embeddingsOk\n"
     ]
    }
   ],
   "source": [
    "index_name = 'askadocument'\n",
    "vector_store = insert_of_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684e7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
